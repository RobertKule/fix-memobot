# app/llm_service.py - VERSION COMPL√àTE FONCTIONNELLE
import os
import json
import re
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

from datetime import datetime
load_dotenv()

# Configuration
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemma-3-1b-it")

# ======================
# CONFIGURATION LANGCHAIN
# ======================
llm = None
json_parser = None

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
    from langchain_core.exceptions import OutputParserException
    
    # Initialiser LangChain avec Gemini
    if GOOGLE_API_KEY:
        llm = ChatGoogleGenerativeAI(
            model=GEMINI_MODEL,
            google_api_key=GOOGLE_API_KEY,
            temperature=0.2,
            max_output_tokens=2048
        )
        
        # Parser JSON
        json_parser = JsonOutputParser()
        
        print("‚úÖ LangChain avec Gemini configur√©")
    else:
        print("‚ö†Ô∏è GOOGLE_API_KEY non configur√©e")
        llm = None
        json_parser = None
        
except ImportError as e:
    print(f"‚ùå LangChain non disponible: {e}")
    llm = None
    json_parser = None

# ======================
# FONCTIONS AVEC LANGCHAIN
# ======================

def analyser_sujet(sujet_data: Dict[str, Any]) -> Dict[str, Any]:
    """Analyse un sujet avec LangChain"""
    
    if not llm:
        return get_fallback_analysis(sujet_data)
    
    prompt_template = """
    Tu es un expert en √©valuation de sujets de m√©moire universitaire.
    
    Analyse ce sujet de m√©moire:
    
    **TITRE**: {titre}
    **DOMAINE**: {domaine}
    **NIVEAU**: {niveau}
    **FACULT√â**: {facult√©}
    **PROBL√âMATIQUE**: {problematique}
    **DESCRIPTION**: {description}
    **MOTS-CL√âS**: {keywords}
    
    Fais une analyse d√©taill√©e selon ces crit√®res:
    1. Pertinence g√©n√©rale (0-100%)
    2. Points forts (3-5 points)
    3. Points faibles (2-3 points)
    4. Suggestions d'am√©lioration (3-5 suggestions)
    5. Recommandations finales (2-3 recommandations)
    
    R√©ponds en JSON avec cette structure exacte:
    {{
        "pertinence": 85,
        "points_forts": ["point1", "point2", "point3"],
        "points_faibles": ["point1", "point2"],
        "suggestions": ["suggestion1", "suggestion2", "suggestion3"],
        "recommandations": ["recommandation1", "recommandation2"]
    }}
    """
    
    try:
        prompt = ChatPromptTemplate.from_template(prompt_template)
        chain = prompt | llm | json_parser
        
        result = chain.invoke({
            "titre": sujet_data.get('titre', ''),
            "domaine": sujet_data.get('domaine', ''),
            "niveau": sujet_data.get('niveau', ''),
            "facult√©": sujet_data.get('facult√©', ''),
            "problematique": sujet_data.get('problematique', ''),
            "description": sujet_data.get('description', ''),
            "keywords": sujet_data.get('keywords', '')
        })
        
        return result
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur analyse LangChain: {e}")
        return get_fallback_analysis(sujet_data)

def recommander_sujets_llm(
    interests: List[str], 
    sujets: List[Dict], 
    crit√®res: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """Recommande des sujets avec LangChain"""
    
    if not llm or not sujets:
        return fallback_recommendation(interests, sujets)
    
    # Formater les sujets
    sujets_text = ""
    for sujet in sujets[:10]:  # Limiter √† 10 sujets pour le contexte
        sujets_text += f"\n‚Ä¢ ID: {sujet.get('id', 'N/A')}"
        sujets_text += f" | Titre: {sujet.get('titre', 'Sans titre')}"
        sujets_text += f" | Mots-cl√©s: {sujet.get('keywords', '')}"
        sujets_text += f" | Niveau: {sujet.get('niveau', 'N/A')}"
        sujets_text += f" | Domaine: {sujet.get('domaine', 'G√©n√©ral')}"
    
    prompt_template = """
    Tu es un assistant sp√©cialis√© dans la recommandation de sujets de m√©moire.
    
    **PROFIL √âTUDIANT:**
    - Int√©r√™ts: {interests}
    - Niveau: {niveau}
    - Facult√©: {facult√©}
    - Domaine: {domaine}
    - Difficult√©: {difficult√©}
    
    **SUJETS DISPONIBLES:**
    {sujets_text}
    
    **T√ÇCHE:**
    Pour les sujets les plus pertinents, fournis:
    1. Score de pertinence (0-100) bas√© sur les int√©r√™ts et crit√®res
    2. 2-3 raisons principales de recommandation
    3. Crit√®res d'acceptation respect√©s
    
    **FORMAT DE R√âPONSE (JSON):**
    [
      {{
        "id": 1,
        "score": 85,
        "raisons": ["Raison 1", "Raison 2"],
        "crit√®res": ["Crit√®re 1", "Crit√®re 2"]
      }}
    ]
    
    Retourne seulement les 3-5 sujets les plus pertinents, tri√©s par score d√©croissant.
    """
    
    try:
        prompt = ChatPromptTemplate.from_template(prompt_template)
        chain = prompt | llm | StrOutputParser()
        
        response = chain.invoke({
            "interests": ", ".join(interests) if interests else "Non sp√©cifi√©",
            "niveau": crit√®res.get('niveau', 'Non sp√©cifi√©'),
            "facult√©": crit√®res.get('facult√©', 'Non sp√©cifi√©e'),
            "domaine": crit√®res.get('domaine', 'Non sp√©cifi√©'),
            "difficult√©": crit√®res.get('difficult√©', 'Moyenne'),
            "sujets_text": sujets_text
        })
        
        # Parser le JSON de la message
        try:
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                return result
        except (json.JSONDecodeError, AttributeError) as e:
            print(f"‚ö†Ô∏è Erreur parsing JSON: {e}")
            
        return fallback_recommendation(interests, sujets)
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur recommandation LangChain: {e}")
        return fallback_recommendation(interests, sujets)

def r√©pondre_question(question: str, contexte: str = None) -> str:
    """R√©pond √† une question avec LangChain"""
    
    if not llm:
        return "Le service IA est temporairement indisponible. Veuillez consulter votre enseignant pour des conseils personnalis√©s."
    
    prompt_template = """
    Tu es un expert-conseil en sujets de m√©moire universitaire, appel√© MemoBot.
    Tu aides les √©tudiants √† trouver, affiner et d√©velopper leurs sujets de m√©moire.
    
    **QUESTION DE L'√âTUDIANT:**
    {question}
    
    {contexte}
    
    **INSTRUCTIONS:**
    1. Donne une message claire, concise et utile
    2. Propose des conseils pratiques si pertinent
    3. Sois encourageant et professionnel
    4. R√©ponds en fran√ßais de mani√®re naturelle
    5. Si la question est vague, demande des pr√©cisions
    6. Tu peux sugg√©rer des pistes de r√©flexion
    
    **R√âPONSE:**
    """
    
    try:
        prompt = ChatPromptTemplate.from_template(prompt_template)
        chain = prompt | llm | StrOutputParser()
        
        contexte_text = f"**CONTEXTE SUPPL√âMENTAIRE:**\n{contexte}" if contexte else ""
        
        message = chain.invoke({
            "question": question,
            "contexte": contexte_text
        })
        
        return message
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur message LangChain: {e}")
        return f"Je ne peux pas r√©pondre pour le moment. Veuillez r√©essayer plus tard."

def g√©n√©rer_sujets_llm(params: Dict[str, Any], count: int) -> List[Dict[str, Any]]:
    """G√©n√®re des sujets avec LangChain"""
    
    if not llm:
        return generate_default_subjects(params, count)
    
    prompt_template = """
    Tu es un g√©n√©rateur de sujets de m√©moire universitaires.
    
    **SP√âCIFICATIONS:**
    - Int√©r√™ts: {interests}
    - Domaine: {domaine}
    - Niveau: {niveau}
    - Facult√©: {facult√©}
    - Nombre de sujets: {count}
    
    **EXIGENCES POUR CHAQUE SUJET:**
    1. Un titre pr√©cis et accrocheur
    2. Une probl√©matique claire et pertinente
    3. 5-7 mots-cl√©s s√©par√©s par des virgules
    4. Une description concise (2-3 phrases)
    5. Une m√©thodologie sugg√©r√©e
    6. Une difficult√© (facile/moyenne/difficile)
    7. Une dur√©e estim√©e (ex: 3-6 mois)
    
    **FORMAT DE R√âPONSE (JSON):**
    [
      {{
        "titre": "Titre du sujet",
        "probl√©matique": "Probl√©matique de recherche",  // CHANG√â: probl√©matique au lieu de problematique
        "keywords": "mot1, mot2, mot3, mot4, mot5",
        "description": "Description du sujet",
        "methodologie": "M√©thodologie sugg√©r√©e",
        "difficult√©": "moyenne",
        "dur√©e_estim√©e": "6 mois"
      }}
    ]
    
    G√©n√®re exactement {count} sujets originaux, pertinents et r√©alisables.
    """
    
    try:
        prompt = ChatPromptTemplate.from_template(prompt_template)
        chain = prompt | llm | StrOutputParser()
        
        response = chain.invoke({
            "interests": params.get('interests', 'Recherche acad√©mique'),
            "domaine": params.get('domaine', 'G√©n√©ral'),
            "niveau": params.get('niveau', 'L3'),
            "facult√©": params.get('facult√©', 'Sciences'),
            "count": count
        })
        
        # Parser le JSON
        try:
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                sujets = json.loads(json_str)
                
                # Ajouter les champs manquants pour correspondre au sch√©ma
                for i, sujet in enumerate(sujets):
                    sujet["domaine"] = params.get('domaine', 'G√©n√©ral')
                    sujet["niveau"] = params.get('niveau', 'L3')
                    sujet["facult√©"] = params.get('facult√©', 'Sciences')
                    sujet["original"] = True
                    sujet["generated_at"] = datetime.utcnow().isoformat()
                    
                return sujets[:count]
        except (json.JSONDecodeError, AttributeError):
            pass
            
        return generate_default_subjects(params, count)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur g√©n√©ration LangChain: {e}")
        return generate_default_subjects(params, count)


def get_acceptance_criteria() -> Dict[str, Any]:
    """
    Retourne les crit√®res d'acceptation des sujets de m√©moire
    """
    return {
        "crit√®res_acceptation": [
            "Pertinence avec le domaine d'√©tude de l'√©tudiant",
            "Probl√©matique clairement d√©finie et sp√©cifique",
            "Originalit√© et valeur ajout√©e par rapport √† l'√©tat de l'art",
            "Faisabilit√© technique (ressources disponibles)",
            "Faisabilit√© temporelle (6-12 mois maximum)",
            "Acc√®s aux donn√©es et mat√©riaux n√©cessaires",
            "Int√©r√™t scientifique et/ou pratique d√©montr√©",
            "Ad√©quation avec le niveau acad√©mique",
            "Objectifs de recherche SMART",
            "M√©thodologie appropri√©e et bien d√©finie"
        ],
        "crit√®res_rejet": [
            "Sujet trop large, vague ou mal d√©fini",
            "Duplication d'un travail existant sans valeur ajout√©e",
            "Ressources insuffisantes ou inaccessibles",
            "Probl√©matique absente, floue ou mal formul√©e",
            "Aspects non-√©thiques ou non conformes",
            "Hors du domaine de comp√©tence",
            "Objectifs irr√©alistes ou trop ambitieux",
            "Manque d'encadrement disponible",
            "Co√ªt trop √©lev√© sans financement",
            "D√©lai incompatible avec le calendrier acad√©mique"
        ],
        "conseils_pratiques": [
            "Consultez votre directeur potentiel d√®s le d√©but",
            "Effectuez une revue de litt√©rature pr√©liminaire",
            "D√©finissez une m√©thodologie r√©aliste",
            "√âtablissez un calendrier d√©taill√©",
            "Identifiez pr√©cis√©ment les ressources n√©cessaires",
            "Assurez-vous d'avoir les comp√©tences requises",
            "Pr√©voyez des alternatives en cas de difficult√©s",
            "Documentez votre processus de recherche",
            "Pr√©parez une soutenance professionnelle",
            "Anticipez les questions du jury"
        ]
    }

# ======================
# FONCTIONS DE SECOURS
# ======================

def get_fallback_analysis(sujet_data: Dict[str, Any]) -> Dict[str, Any]:
    """Analyse de secours sans IA"""
    return {
        "pertinence": 75,
        "points_forts": [
            f"Sujet dans le domaine: {sujet_data.get('domaine', 'G√©n√©ral')}",
            "Probl√©matique identifi√©e dans les donn√©es",
            f"Niveau adapt√©: {sujet_data.get('niveau', 'L3')}"
        ],
        "points_faibles": [
            "Analyse automatique limit√©e sans IA",
            "Suggestions g√©n√©riques",
            "Validation humaine requise"
        ],
        "suggestions": [
            "Consulter un enseignant r√©f√©rent pour validation",
            "Pr√©ciser la m√©thodologie de recherche",
            "D√©finir des objectifs sp√©cifiques et mesurables"
        ],
        "recommandations": [
            "Sujet potentiellement int√©ressant √† approfondir",
            "Valider la faisabilit√© avec un expert",
            "√âtudier des travaux similaires pour inspiration"
        ]
    }

def fallback_recommendation(interests: List[str], sujets: List[Dict]) -> List[Dict[str, Any]]:
    """Recommandation de secours sans IA"""
    results = []
    
    if not sujets:
        return results
    
    for sujet in sujets[:5]:
        score = 0
        matching_points = []
        
        # V√©rifier les correspondances
        titre = sujet.get('titre', '').lower()
        keywords = sujet.get('keywords', '').lower()
        domaine = sujet.get('domaine', '').lower()
        
        for interest in interests:
            interest_lower = interest.lower()
            
            # Score pour correspondance dans le titre
            if interest_lower in titre:
                score += 30
                matching_points.append(f"Int√©r√™t '{interest}' dans le titre")
            
            # Score pour correspondance dans les mots-cl√©s
            if interest_lower in keywords:
                score += 25
                matching_points.append(f"Int√©r√™t '{interest}' dans les mots-cl√©s")
            
            # Score pour correspondance dans le domaine
            if interest_lower in domaine:
                score += 20
                matching_points.append(f"Int√©r√™t '{interest}' dans le domaine")
        
        if score > 0:
            results.append({
                "id": sujet.get("id", 0),
                "score": min(score, 100),
                "raisons": matching_points[:3] if matching_points else ["Correspondance g√©n√©rale"],
                "crit√®res": [
                    "Matching automatique par mots-cl√©s",
                    f"Niveau: {sujet.get('niveau', 'N/A')}",
                    f"Domaine: {sujet.get('domaine', 'N/A')}"
                ]
            })
    
    # Trier par score
    results.sort(key=lambda x: x["score"], reverse=True)
    return results

def generate_default_subjects(params: Dict[str, Any], count: int) -> List[Dict[str, Any]]:
    """G√©n√®re des sujets par d√©faut"""
    domaine = params.get('domaine', 'Informatique')
    niveau = params.get('niveau', 'Master')
    facult√© = params.get('facult√©', 'Sciences')
    interests = params.get('interests', 'Recherche acad√©mique')
    
    subjects = []
    for i in range(1, count + 1):
        subjects.append({
            "titre": f"Application de l'IA dans le domaine du {domaine}",
            "probl√©matique": f"Comment l'intelligence artificielle peut-elle transformer les pratiques et processus dans le {domaine} ?",  # CHANG√â
            "keywords": f"IA, {domaine}, transformation, innovation, technologie",
            "description": f"√âtude des applications potentielles de l'intelligence artificielle dans le secteur du {domaine}, avec une analyse des impacts et des d√©fis √† relever.",
            "methodologie": "Revue de litt√©rature, analyse comparative, √©tude de cas",
            "difficult√©": "moyenne",
            "dur√©e_estim√©e": "6 mois",
            "domaine": domaine,  # AJOUT√â
            "niveau": niveau,    # AJOUT√â
            "facult√©": facult√©,  # AJOUT√â
            "original": True,    # AJOUT√â
            "generated_at": datetime.utcnow().isoformat()  # AJOUT√â
        })
    
    return subjects

def get_tips() -> Dict[str, List[str]]:
    """
    Retourne des conseils pour la r√©daction de m√©moire
    """
    return {
        "choix_sujet": [
            "Choisissez un sujet qui vous passionne vraiment",
            "Assurez-vous que le sujet soit ni trop large ni trop √©troit",
            "V√©rifiez la disponibilit√© des ressources",
            "Le sujet doit apporter une contribution originale",
            "Consultez votre directeur potentiel avant de finaliser"
        ],
        "methodologie": [
            "D√©finissez clairement votre probl√©matique de recherche",
            "Choisissez une m√©thodologie adapt√©e √† votre question",
            "√âlaborez un plan de recherche d√©taill√©",
            "Documentez rigoureusement toutes vos sources",
            "Testez votre m√©thodologie sur un √©chantillon r√©duit"
        ],
        "redaction": [
            "Structurez votre m√©moire de mani√®re logique",
            "R√©digez r√©guli√®rement (un peu chaque jour)",
            "Utilisez un style acad√©mique clair et pr√©cis",
            "Citez vos sources selon les normes",
            "Faites relire votre travail par d'autres"
        ],
        "soutenance": [
            "Pr√©parez votre pr√©sentation bien √† l'avance",
            "Structurez votre pr√©sentation clairement",
            "Entra√Ænez-vous plusieurs fois √† pr√©senter",
            "Pr√©parez un support visuel professionnel",
            "Anticipez les questions du jury"
        ]
    }

# ======================
# TEST DE CONNEXION
# ======================

if __name__ == "__main__":
    print("üß™ Test de LangChain avec Gemini...")
    
    if llm:
        try:
            # Test simple
            prompt = ChatPromptTemplate.from_template("R√©ponds simplement 'OK' si tu fonctionnes.")
            chain = prompt | llm | StrOutputParser()
            response = chain.invoke({})
            print(f"‚úÖ LangChain fonctionne: {response}")
            
            # Test des fonctions
            print(f"\nüìã Fonctions disponibles:")
            print(f"  - r√©pondre_question: ‚úì")
            print(f"  - analyser_sujet: ‚úì")
            print(f"  - g√©n√©rer_sujets_llm: ‚úì")
            print(f"  - get_acceptance_criteria: ‚úì")
            print(f"  - get_tips: ‚úì")
            
        except Exception as e:
            print(f"‚ùå Erreur test LangChain: {e}")
    else:
        print("‚ö†Ô∏è LangChain non configur√©, mode fallback activ√©")
    
    print("\n‚úÖ Module llm_service pr√™t")